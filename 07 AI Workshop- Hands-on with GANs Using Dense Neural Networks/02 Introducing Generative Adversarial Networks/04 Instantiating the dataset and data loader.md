Instantiating the dataset and data loader
Let's get started writing some code. We have a notebook server running and I have a notebook open. And remember, this notebook uses the pytorch_venv virtual environment. The first thing that I need to do here is import all of the libraries that we'll be using in this course torch, torchvision, torch.nn, that's what we'll use to define our neural network layers. From torchvision, we'll import the transforms library that will allow us to transform the images that we read in. And tqdm is the library used to display progress bars needed during training. Next, let's create a new subfolder called data right within our current working directory. This is the folder that we'll use to download and store the images that we'll use to train our generative adversarial network. Run this code and let's check to make sure that the data folder is indeed present. You can see the data folder present there. And if you click through, you'll find that this folder is completely empty. Once we download the data, I suggest you come back and look in this folder and you will find some zip files for our data in there. Let's switch back to our notebook. The images that we'll use to train our GAN are going to be single-channel images or grayscale images. That means the images will only be in black or white. There'll be no color in those images. Now, this makes sense if you're building and training again using a dense neural network as we are in this demo. Dense neural networks don't really work well with image data, but with simpler images, you'll still be able to see how the GAN functions. Of course, if you have more complex multi-channel images, you should be using a deep convolutional GAN, a GAN built using convolutional layers. Now, you may have heard of the MNIST dataset of grayscale images, which is a widely used collection of handwritten digits, and it serves as a benchmark dataset in the field of machine learning and computer vision. Now, we'll work with a slightly more complex grayscale dataset, the Fashion-MNIST dataset. Fashion-MNIST is based on the original MNIST dataset. It comprises of 60,000 training images and 10,000 test images, exactly like the original MNIST, except that these images belong to ten different fashion categories such as t-shirts, dresses, sneakers, and others. This is available as a built-in dataset in PyTorch, and before we read in that dataset, let's define the transformations that we want to apply to the grayscale images so that we can use the data for GAN training. We'll read the images in as NumPy arrays, transforms.ToTensor will convert those images to PyTorch tensors, and transforms.Normalize will scale the dataset so that they're centered around zero. The pixels in grayscale images represent intensity values and are usually expressed in the range zero to one. We assume that the mean of the Fashion-MNIST grayscale dataset is 0.5, and the standard deviation is 0.5. So we subtract the mean and divide by the standard deviation to express the data in terms of standard deviations away from the mean and center the image pixel values around zero. Centering our image data around zero and expressing pixel values in terms of standard deviations from the mean will improve the training of our neural network. The next step is to access the Fashion-MNIST data, and this can be done by instantiating the torchvision.datasets.FashionMNIST object. Root points to the data folder that we've just created. That's where the dataset will be downloaded and stored. Train is equal to true will download the training dataset, the 60,000 images. Transform equals to transform will apply the transformations that we had defined to the input image data. Download is equal to true will ensure that the data is accessed from wherever it's stored on the remote server, and download it to our local machine. Running this code will instantiate a PyTorch dataset, which represents a collection of data samples that we'll use to train our model. You may have to wait about a minute or so till all of the gzip file for this data is downloaded and stored on your local machine. And once we have a dataset, we can use that to instantiate a PyTorch DataLoader. The DataLoader is a utility that provides an efficient way to load and iterate over data samples from a PyTorch dataset during training, validation, or testing of machine learning models. Here we instantiate a torch.utils.data.DataLoader. The dataset that we point to is the Fashion-NIST dataset. The batch size is 16, so that there'll be 16 images for every batch of data. Shuffle is true. The images will be shuffled when we iterate over them. drop_last equal to true will drop the entire last batch of images if there are fewer images in that batch than the batch size. Once the DataLoader has been instantiated, we can now iterate over our image samples in batches. Let's take a look at the length of the DataLoader, and you can see here that the length is 3750. There are 60,000 images in the training data, 60,000 divided by 16 gives us 3750. Remember, the last batch with fewer samples than the batch size will be dropped.