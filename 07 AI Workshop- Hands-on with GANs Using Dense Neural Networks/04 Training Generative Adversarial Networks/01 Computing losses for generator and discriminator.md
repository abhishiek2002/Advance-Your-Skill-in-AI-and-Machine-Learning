Computing losses for generator and discriminator
Training a GAN requires juggling training for both the generator and the discriminator. Both of them have to be trained together, alternating one with the other. The generator and the discriminator both have different objectives, which means that the loss functions have to be set up accordingly to capture these objectives. When you train a GAN, you work with two different loss functions: One loss function for the generator and another loss function for the discriminator. Now, before we get into the intuition of these loss functions, let's understand the sources of data for the discriminator. The discriminator gets data from two sources: Real data instances from a real data set, and fake data instances generated by the generator. What is it that the discriminator tries to optimize? The discriminator would like to maximize the probability of it classifying the real data as real, and minimize the probability of classifying fake data as fake. The discriminator wants to get its classification right. Real data should be thought of as real, and fake data should be thought of as fake. The loss function of the discriminator should be so set up that this duality is captured. The discriminator should be penalized for misclassifying data. So if it identifies real images as fake or fake images as real, the discriminator needs to pay a penalty. The discriminator's loss is computed on the real data as well as the fake data, and this loss or error is used to update the discriminator weights in the backward pass through the model. The backpropagation through the discriminator network is used to update the discriminator's model parameters. The discriminator's working is relatively straightforward. Next, let's talk about how the generator works. The generator cannot be trained standalone, and there is very tight integration between the generator and the discriminator. How does the generator work? We feed in random noise as an input to the generator, and then the generator uses that noise to generate an image or data. The discriminator then classifies the generated data, and the objective of the generator is to have its generated data classified as real by the discriminator. The generator during the training process is penalized for not fooling the discriminator. The objective of the generator during the training process is different. The generator tries to maximize the probability that the fake data that it has generated is classified as real by the discriminator. The generator tries to influence the discriminator output by generating better and better quality samples. Now, when we compute the loss function for the generator, that's actually based on the discriminator's classification of the fake data that the generator produced. So the loss is actually based on the discriminator's output. So when we make a backward pass through the generator, this involves the discriminator network, as well. Gradients are computed on the generator network and the backward pass is made through the discriminator. The discriminator weights are, of course, not updated here. Only the generator weights are updated. So what's the loss function that a GAN uses? The original paper uses a type of loss function known as the minimax loss. Minimax because the generator tries to minimize the loss function and the discriminator maximizes the same function. We'll talk more about the minimax loss later on in this course. The minimax loss in its original form is not ideal for GAN training. GANs may stuck in very early stages of training when the minimax loss is used in its original form. A modified version of the loss called the modified minimax loss is often used and that has proven to get better results. Another loss function that has been researched and found to be better than the minimax loss is the Wasserstein loss. With this loss function, the discriminator actually does not classify instances as real or fake. Instead, the discriminator outputs a number for each instance and the output will be larger for real instances and the number that's output for fake instances will be smaller. When the Wasserstein loss is used, the discriminator is often referred to as the critic. That's because the discriminator will give high scores to real data and low scores to fake data.