Visualizing GAN training results
At this point, we've set up the code to train our generative adversarial network. Let's go ahead and execute this code and see how our network trains. At the very beginning, this is very early on in epoch zero, the discriminator performs really well. Notice that the discriminator's loss on real images and fake images are both very close to zero, 0.0 and 0.168, respectively. The generator's loss is pretty large 1.972. The discriminator score on the real images one, fake score close to zero, so 0.0154, and the fake score after the discriminator has been updated is 0.148. At this point, the discriminator is doing really well, the generator has not started generating convincing fakes, yet. You can see a sample of images generated by the generator. It's just noise at this point. But within the same epoch, you will start seeing the generator improve. Notice that the images generated by the generator have shown a little bit of improvement. Still noise at this point, but better than before. Let's keep observing and let's go straight to Epoch 1. And here if you look at the generator images, you can see some semblance of fashion accessories forming. Observe that the real score is coming down from one. The fake score is moving away from zero, and the fake score after the discriminator update is also moving away from zero. The discriminator's total loss is 0.21. It's slowly inching up, the generators loss is high 4.9, but you will find that inching down. Let's continue and let's go to the beginning of the next epoch, Epoch 2. First, let's observe the images. You can actually see a sneaker there, a pair of heels somewhere else, some boots, some coats. The discriminator's total loss is 1.283. It has crept up. The generator's loss has fallen, 1.646. That's because the generator is getting better at generating fake images. The discriminator's real score has fallen to 0.82, fake score has moved up to 0.48, and the fake score of the discriminator update has also moved up to 0.27. And this trend is going to continue. On my local machine, the training ran for about 30 to 40 minutes. You can see the images being generated are getting better over time. Here at Epoch 37, I would say the images generated are getting to be pretty good. The discriminator's total loss is 1.299, but the generator loss has fallen to 0.849. The discriminator has gotten steadily worse over time. Its score on the real and fake data are both approaching 0.5; 0.477 and 0.410, respectively. The discriminator is close to guessing at random what image is real and what image is fake, while the generator has been steadily improving. Let's go to the beginning of the very last epoch here, Epoch 39, and here you can see that real score and fake score are both near 0.5. At this point, if you look at the images generated by the generator, they are pretty good. You can actually identify a bag, trousers, sneakers, and so on. And at the end of Epoch 39, the images are even better. Epoch 39 here refers to the 40th epoch and that is the end of our training. Now, GAN training convergence is kind of hard to measure because if you train GANs beyond a point, because the discriminator is performing so poorly, the generator fails to improve and starts getting worse. So you have to train until the point until you feel the generator is improving and stop before it gets worse. Now that we have trained our generator and discriminator, let's visualize the loss and accuracy of both of these individual models. I'll plot two plots side by side. The first one will plot the generator loss and the discriminator loss, and you'll see how they change over time. And the next one will plot the real score and the fake score from the discriminator. And we'll see how those have changed over time, as well. Let's take a look at this visualization. First, let's take a look at how the loss moves for the generator and the discriminator. The generator loss is in blue. The discriminators loss is an orange. As training progresses, the generator's loss falls over time as it improves and generates better fake images. The discriminator's loss increases over time because it gets steadily worse at predicting which images are fake and which images are real. On the right, we have the discriminator's accuracy scores on the real and fake data. The real score is in blue, the fake score is in orange. Early on, the discriminator does very well. The real scores are close to one and the fake scores are close to zero. But as the generator improves the quality of its fakes, the discriminator starts performing worse. And towards the end, you can see that real scores and fake scores both converge to about 0.5. At the end, the discriminator is just predicting at random. It's not that much better than a coin toss.