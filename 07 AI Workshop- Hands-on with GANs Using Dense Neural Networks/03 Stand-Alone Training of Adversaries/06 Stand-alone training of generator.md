Stand-alone training of generator
In this movie, we'll train the generator standalone without training the discriminator, and you'll find that the generator keeps training, but it will not improve at all. The images that it will generate will continue to be bad fakes, and the reason for that is that the discriminator is not really helping the generator improve. Since we're not training the discriminator, the discriminator continues to make random predictions. So randomly the generator's output may be classified as real or fake and the generator essentially just ends up spinning its wheels. In real life, we improve with feedback, and this is true of the generator, as well. Because the discriminator is not able to provide constructive feedback since it's not being trained, the generator basically gets stuck in a bad place and continues to generate bad fakes. First, I'm going to set up a utility function called display_image_grid to display a grid of the generated images at a particular epoch. We unnormalized the images on Line 2, we create a grid of the generated images on Line 4, we swap around the dimensions of the image so that they are in a format matplotlib can plot, that's the code on Line 5. On Line 6, we convert the PyTorch tensors to NumPy, and then we plot the image. In order to ensure that we start this from scratch, I'm going to reinitialize the generator and discriminator networks. I also instantiate the Adam optimizer for the generator and discriminator parameters. With this done, let's see the code to train the generator standalone. The generator will be trained but not the discriminator, so make sure you call netG.train so that it's in training mode. The discriminator will be in eval mode. No gradients will be computed on the discriminator. It will not be trained. Now, I'm going to train for five epochs, but you can train for 50 epochs if you want to. The generator will not improve unless the discriminator is also trained at the same time. The for loop on Line 9 iterates through epochs of training. The for loop on Line 11 iterates through the batches of training data. Now, in order to generate fake images, we need to initialize the latent noise variables, that's done on Line 14. On Line 16, we pass the noise as an input to the generator, make a forward pass through the model, and get the generated fake images. Now, remember we want the discriminator to identify these as real, so I set up a batch of real labels on Line 17. On Line 19, I zero out the gradients of the generator, and on Line 21, I get the predictions of the discriminator on the fake images, that is the output from the discriminator. On Line 25, we compute the generator error. The objective of the generator network is to maximize the probability that the discriminator classify fake images as real. So notice the criterion here is that the output of the discriminator should be the real labels, and this is the loss the generator will try to minimize. On Line 28, we make a backward pass through the generator to compute the gradients for that network. D_G_z2 computes the mean of the output predictions made by the discriminator. Remember, in the ideal world, the generator will want the discriminator to predict that fake images are all real. The generator wants the D_G_z2 score to be close to one. g_optimizer.step will update the gradients of the generator. After 100 batches of training, we'll print out the epoch, the loss of the generator, and the discriminator score on the fake data, and we'll also log out the current batch of fake images that the generator produced. So we'll see whether the generator improves over time. And we'll use the display_image_grid function for this. Go ahead and execute this code cell, and let's start the training process. The discriminator score on the fake images is 0.292. In the next batch of 100, the fake score becomes 0.998. So the discriminator basically thinks that the generator is producing great fakes. And because it does not give critical feedback to the generator, notice that the generator simply does not improve. Even after epochs and epochs of training, the fakes generated by the generator continue to be pretty horrible. Really, you can't say that these look anything like the Fashion-MNIST images. So essentially, without critical feedback from the discriminator, the generator does not improve. It should be pretty clear to you that training either the discriminator standalone or the generator standalone does not make sense for a generative adversarial network. If you want the generator to generate good images, which are very realistic, you need to train the generator and discriminator together.