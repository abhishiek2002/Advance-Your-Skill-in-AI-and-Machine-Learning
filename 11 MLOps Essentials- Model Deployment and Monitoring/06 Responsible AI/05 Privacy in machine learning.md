Privacy in machine learning
- [Instructor] Similar to security, privacy is another important consideration in machine learning. Sensitive information should be protected against accidental or adversary leakage when used for training or inference. While security deals with protecting the entire data set or model, privacy focuses on protecting the sensitive parts while still providing access to the other parts for authorized users, like data scientists and analysts. Why do we need privacy protections? As the applications of AI are growing, so is the concern around its ability to infringe upon the rights and privacy of individuals. The first concern for building ML solutions is to gain customer and user trust. Users are worried about the misuse of their private data, and hence are unwilling to share this information for model training. There is concern around who gets to see their private data and if those individuals may steal and use it for unethical purposes. There is a growing compliance framework across the world for AI. More and more laws, regulations and standards are created like GDPR, and HIPAA. Each country is coming up with their own laws for AI, and business verticals like healthcare and banking are also doing the same. Compliance to these is a requirement in order to sell ML products to these countries and verticals. What are the various techniques available for privacy protection? It begins with having access controls, specifically at an attribute level. Anonymization of data is another technique where real values are replaced with mapped ones so that the patterns are retained by not exposing real information. Data aggregation is another technique to hide individual information. Threat modeling and leakage analysis helps identify gaps in privacy implementation and fix them. Federated learning and inference is another area that takes the model to where the data is. The model can do its job with the data staying in its own trust zone. Differential privacy is an area that is becoming popular too. It focuses on manipulating outputs from data, such that data leakage and reverse engineering are not possible. Finally, education for all stakeholders is an understated but very important requirement to ensure that everyone understands the risk around privacy and ensures its protection in their work.