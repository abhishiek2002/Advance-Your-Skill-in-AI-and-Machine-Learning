Introduction to model drift
- [Instructor] In this chapter, we will explore in detail about model drift and ways to monitor it. Let's begin with an introduction to model drift. When we train, test, and deploy a model, it has a proven level of predictive accuracy. It is expected that the model will continue to have the same accuracy levels in production over its lifetime. A model is considered drifting when its predictive accuracy reduces over time when deployed in production. Let's consider a few examples here. We have three models deployed in production at month zero. The chart shows the observed prediction accuracy of models for the next four months. Let us start with the first model, sentiment analysis which is the green lane. It starts with an accuracy of 85%, and over the next four months, it oscillates between 85% and 90%. It is staying within the band, and hence considered not drifting. Next, let's look at the intent detection model shown in red. It starts with an accuracy of 85%, but in the second month, its observed accuracy falls to 65% and then stays around there. This is considered a sudden model drift. Next, we look at the obscenity filter in blue. This model starts at 90% accuracy, and its accuracy goes down slowly over time to 75%. This is called slow drift or slow decay over time. When a model is deployed in production, all these types of drift can happen. But if the models accuracy goes down for a given time period but comes back into the band for the next, it is not considered as a drift. To help with our discussions around drift, let's discuss some math on prediction probabilities. Let us assume that we have a simple model that takes in features about a patient and predicts if the patient has diabetes. One of the features is the age of the patient. x stands for a feature and y stands for the target. So the probability of x or p of x is the probability that a given feature value appears in the population. So if 40% of the patients are older than 50, then the probability of age greater than 50 would be 40%. Similarly, the probability of y or p of y is the probability that a given target value occurs in the population. So if 10% of the patients have diabetes, then the probability of diabetes equal to true is 10%. We then look at conditional probabilities. The probability of x given y or p of x given y means how often a given value of x occurs when a given value of y occurs. This means the percentage of time when age is greater than 50 when the patient has diabetes. The reverse conditional probability is p of y bar x. This is the probability that the patient has diabetes when their age is greater than 15. The joint probability of x and y is the percentage of time that both x and y values occur in the dataset. In this example, it is the percentage of time that a patient has diabetes and also of age greater than 15. The probability of y given x or p of y bar x is computed as the joint probability of x and y divided by the probability of x. This is the formula that indicates the relationship between a specific value for a feature and a specific outcome for the target. Drift happens when the probability of y given x changes in the real world, but the model does not reflect the same. For example, let's say after the model is developed and deployed, a magical medication for diabetes is introduced. Because of which, patients about the age 50 have recovered from diabetes. The model will then not be in sync with the change and will continue to predict with the older assumptions. Hence, it'll drift and decay. We will explore drift further in the remaining videos in this chapter.