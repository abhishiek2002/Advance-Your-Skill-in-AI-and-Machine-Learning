Building resiliency in serving
- [Instructor] Resiliency of software is its ability to handle issues gracefully and continue to provide the services to the end user with minimal interruptions. Resiliency is a critical yet overlooked part of model inference. It is key to successful operation of ML services. Without resiliency, these services would suffer from inconsistency, customer concerns, and loss of value. Resiliency should be built at a model, service, and solution levels. Let's begin with model resiliency. Model resiliency is the ability of the model to overcome issues with input data or resources, and continue to maintain the expected performance and operational goals. How do we ensure model resiliency? First, all input that is received during inference need to be validated to make sure that they comply with expected sanctity of data. This includes checking for exceptions, unknown values, out of distribution values, et cetera. Inference data should come from the same distribution as the training data, and any exceptions there should be flagged. Next, track resource utilization by the model to identify capacity issues and rectify them. Monitor the operational metrics of the model, and ensure that they are within expected thresholds. Measure model drift and look for decay. Finally, analyze the model performance for bias and take corrective actions. We will discuss metrics, drift, and bias in the upcoming chapters. Service resiliency deals with the ability of a service to continue its operations and deliver results when issues happen during its runtime. To ensure resiliency against node failures, add redundant nodes for tasks and services. This compensates for any lost capacity. Implement auto scaling to handle sudden changes in service loads. Alternatively, throttle incoming requests so that sudden bursts of requests do not choke the service. For safeguarding against site level failures, create dual redundancy by deploying in multiple locations. Storage disk can also have outages resulting in loss of data. For this, used redundant storage schemes like RAID and sharding to handle disk outages. Solution resiliency deals with the overall experience of the user with the ML solution. User experience should not be impacted when individual models or services experience issues. When issues happen, it is important to analyze its impact on end user experience and take action. Create multi-region deployments of the entire solution to overcome site level failures. Load balance user requests across multiple other regions when there are service issues in one specific service. Use circuit breakers in clients to overcome broken connection issues where the client would indefinitely wait for the server resource. When specific services or models are down, provide alternate functionality to the users so they continue to function with degraded capabilities. For example, if a realtime recommendation engine is down, the recommendations can be served based on an old recommendations cache.