Challenges of governing AI
- [Educator] We discuss the challenges of bringing governance into action, and those discussions are happening across the globe. And that's a key point, it's not just AI governance, but global AI governance. Several countries are working on designing regulatory frameworks and resorting to global collaboration to build a shared and cooperative governance goal. However, such shared governance requires global consensus, which is achievable through dialogue and cooperation. But it requires focusing on a singular goal, that is, building AI for the betterment of society. As dialogues are ongoing among global think tanks, policy makers, researchers, and technology providers, the countries are also discerning whether existing laws can be amended to address the emerging risk from AI or whether it calls for a law offered soon. The answer to this question is a challenge as the risks are rapidly emerging, making it difficult to foresee them all. Additionally, the more institutions, authorities, actors, or stakeholders that become involved and bring out the varied policies and norms, the more complicated, AKA, fragmented it becomes. Yes, you get it right. It becomes fragmented in terms of bringing coherence among all. Saving us from such risk of fragmentation and discordance, it is important to reduce the diversity of regulation at a global scale. The brain power needed to bring rational governance is achievable through a consortium or an advisory body consisting of technology executives, government officials from different countries and academics from various AI related disciplines. It is possible. We just need to promote the right goal, an exchange of thoughts toward equitable and trustworthy AI instead of exchanging competitive signals. I understand that AI as a technology is the most powerful thing of all times. The nation that gets AI right, both in terms of innovation while balancing its need to govern, will be no less than a home of tech superpower, and we all like to wield power, right? But I also know that it is difficult to heal the benefits of AI alone for two reasons. AI has made the world global, which by its very nature extends to cooperation with other nations that contribute diverse expertise, including regional perspectives and opinions to make AI work worldwide. It is only then do we overcome what I call governance silos, something that works for only one part of the world. We certainly do not want to land ourselves in a situation that gives rise to varied multiple divergent initiatives. Moreover, the lines quickly get blurred from regulating how AI is used. For example, in healthcare or hiring, to regulating processes that rely on AI, such as facial recognition or cybersecurity. Another consideration towards making AI safe is its intertwined nature. Its benefits and harms are so infused that regulating them requires careful calibration. Take for example facial recognition. It is used for all things security, essentially authenticating an individual for authorized access, while entering a secure facility or making financial transactions. Most commonly, we see it at airport check-ins. It has its benefits in the form of streamlining operations. However, the other side of it also involves the privacy concerns of the individuals when their facial features are analyzed and collected Without their consent, it becomes a matter of breaching personal privacy. The harms do not stop here and have repercussions downstream too. If such store data is later used for training algorithms, it can perpetuate biases and lead to discriminatory outcomes for specific groups if not well represented. The worst can happen when the impact of such personal data goes beyond the training set and haunts the individuals by tracking them under mass surveillance. Who could have thought that the underrepresented group in the training set could lead to higher rates of misidentification, which in turn could lead to wrongdoings for those affected groups. So while facial recognition when done right, like most other AI applications has its benefits, it is deeply infused with the harms that it may bring. Hence, AI safety requires striking a balance between the positive outcomes of AI and mitigating its harms. I believe our discussions thus far have helped you in shaping the framework for AI governance. Now, let's move to action. Stay tuned as you progress towards implementing effective governance measures.