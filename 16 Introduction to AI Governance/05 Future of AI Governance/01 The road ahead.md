The road ahead
- [Instructor] Having developed a good understanding of introducing AI governance into organizational frameworks, we need to discuss the current state of affairs in the AI regulatory landscape. Keep in mind, though, I'm not a lawyer, so if you begin implementing this in your organization, you should seek appropriate legal counsel. Remember we talked about global governance? Nations are working on regulating AI, whether through careful deliberation of introducing new AI laws, or adapting existing ones to deal with AI complexities. Let us start with what is claimed to be the first of its kind law on AI, the EU AI Act. We discussed its different aspects, including the risk grading approach, the timelines on how it started in 2021, and the trilogue with the European Commission, the Council of the European Union, and the European Parliament. First, the trilogue negotiations conclude. We can expect the law to be in full force in 18 to 24 months. That is expected in early 2026. It's not just the EU. With various approaches being discussed globally from voluntary guidance to mandatory rules, all countries are effectively following a risk-based approach at its score, and this approach has its merit too, as not all risk and the damages arising from them are equal. So, compliance standards and penalties should be tailored accordingly to address and mitigate the varying degrees of risk. Canada is another example. It puts increased compliance checks on high-risk systems to minimize the potential harmful effects of AI. The US also follows a risk-based approach through its voluntary AI Risk Management Framework standard, called AI RMF. The US agency, National Institute of Standards and Technology, NIST, facilitates this framework, incorporating trustworthiness into the design, development, use, and evaluation of AI products, services, and systems. While the AI Act is set to become the first of its kind AI law, the US recently released a first of its kind executive order advising different departments and agencies to take additional measures to safeguard AI. Coming from a place of new regulations or where efforts are underway to fill existing gaps countering the complexity of AI risk, the UK is in an exciting space for fostering innovation that promotes industry growth by not heavily regulating it. Another variant of regulating AI comes from China, which proposed enforceable rules with the onset of the GenAI era. What is the variation? It counts under interim, highlighting the upcoming revisions. It currently holds the GenAI service providers responsible for ensuring that AI-generated content aligns with Chinese law. Additionally, public guidelines are available from UNESCO, the OECD AI Principles, and the White House Office of Science and Technologies' Blueprint for an AI Bill of Rights. I highly promote self-regulation and would give a call out to corporate champions such as Microsoft's Responsible AI Standard and Google's Responsible AI Practices. In my early days as an AI ethicist, I used to give an analogy. What if there were a golden standard to vet the quality of AI systems and solutions that ensure their safety and robustness? So, you can rely on its outcomes and know that it is based on the principles of do no harm. Similar to ISO standards that cover almost every product, process, or service imageable, it brings me joy knowing that those days are finally here. Seeing the role of standardization bodies is the progress in the right direction. As the world is coming together to govern AI, the evolving regulatory landscape requires organizations to stay informed with the latest developments and align them with their operational frameworks, but putting change into practice is quite challenging. Next, we will discuss some of the ways organizations can best navigate such swiftly changing requirements.