Logic gates
- In their early days, neural networks were tested with simple functions to see if they were capable of performing the calculations they were designed to perform. This led to implementing logic gates with perceptrons. So let's take a look at a two input AND Gate, and its truth table, which summarizes its behavior. Supposing zero means false and one means true, the gate outputs true only in the case where both inputs are true. You may already be familiar with this, but let's look at it from a totally different angle, as a classification problem. This plot shows four data points. The coordinates of these data points are the values of inputs A and B. Notice that the data points show their category as a zero or a one. This way, a two input classifier may come up with a boundary that divides the categories. So based on this, a perceptron may behave as an AND gate. Let me show you how the classification is possible. The boundary we are seeing in this 2D plot is technically the line where the sigmoid is 0.5. Now, a 3D plot may help making this explanation better. So let's add a third axis, now vertical to express the output of the sigmoid. This will be the category that the perceptron has inferred. So if we apply the sigmoid, all of the data points will be a part of the surface of the sigmoid, like objects lying on this uneven terrain. So once again, the height of these subjects finally determines the category the perceptron assigns to them. The decision plane will be located at the middle of the sigmoid. So here is a valid implementation of a two input AND gate. It's a two input perceptron with the following weights: 10 for both inputs and minus 15 for the bias. I just came up with these weights by aiming to get a negative sum for a result of zero and a positive sum for one. After testing it with my perceptron class, I got the values shown in this table. Notice that I included a column for the weighted sum Z. Those were the values I was aiming for with the weights I used. So as you can see in the Y column, the top three values are very close to zero, so they may be safely rounded to zero, and the last value is almost one. So here's how I tested the perceptron at the bottom of the code. First, I created a perceptron with two inputs in line 29, and then I entered the weights as a list in line 30. Notice the order of the weights, 10 and 10 for the inputs and minus 15 for the bias. That's it. In the rest of the code, I'm testing all four cases with the print function. Let's see it working. If you look at the terminal at the bottom, you'll see something very similar to the truth table of the AND gate. Great. So our perceptron can indeed operate as an AND gate. Let's move on.