Applying convolutional and pooling layers
In this demo, we'll see how we can apply convolutional kernels of different types to the input image and look at the resulting image. We'll also see the result of applying a max pooling layer after we've applied the convolutional kernel. Every kernel that we apply will perform a different operation on the underlying image. For example, this very first kernel here is a sharpened kernel. The sharpened kernel has weights which serve to sharpen the underlying image. Sharpening is a combination of edge detection plus the original image. The sharpened kernel has a sum of one. Now how exactly this kernel sharpens the underlying image? That's a mathematical construct that we won't get into, but we'll focus on how to apply these convolutional filters to the input image and view the result. Observe that I've specified the kernel in four dimensions. This corresponds to the four dimensions in which the original image is expressed. If you remember the original image, that's a 4D tensor as well. Here is the sharpened kernel defined as a matrix. Let's now convert this to a tensor format using torch.Tensor. I've called the resulting tensor the sharpen_filter because it performs a filtering operation on the underlying image, and you can see the dimensions of the sharpen_filter. The F.conv2d function in PyTorch accepts custom filters that you can apply to images. We pass in the images of 4D tensor, we pass in our filter. We don't apply any padding to the input image, and we get the convolutional tensor at the output. Observe that the resulting tensor has batch size equal to one, number of channels equal to one. Our sharpening filter was applied to just one channel, and you can see that the dimensions of the image are a little smaller, 798 pixels along the width, rather than 800. That's because we applied no padding to the input image. Next, from this convolutional tensor, in order to access only the image, I'm going to get rid of the batch size dimension so that we get the image 450 x 798, and one channel. In order to display this image using matplotlib, I'm going to convert the image to a NumPy format so that it's no longer a PyTorch tensor. Here is the image in NumPy, 450 x 798. We are now finally ready to view this image. This image is just a feature map that extracts the sharpened version for a single channel of the underlying image. And here is what the resulting feature map looks like. It's a single channel image, and if you look closely, it does seem much sharper than the original. Our image was a grayscale image, and you might wonder why this particular image is displayed in green. That's because by default, the color map that matplotlib uses for grayscale images is something called Viridis, which is like a greenish color. Convolutional layers in a convolutional neural network are usually followed by pooling layers. Next, let's apply a max pool operation on the input image. And here is the max pool function that I have defined, MaxPool2d. I'll now pass the convolution tensor through the max pool layer. And let's take a look at the shape of the pooling tensor. You can see that it's about half the size of the original feature map, 225 x 399. Now let's extract the image in the pooling layer as well. I'm going to get rid of the first dimension. The next step is to convert this result, the pooled image, to a NumPy array and get rid of the channel as well. So we get a 225 x 399 image. And let's plot this using matplotlib as well. So this is the pooled image. And you can see the slight aggregation of the image, it's slightly blurred as compared to the previous image that was the output of the convolutional layer. And this is how convolutional and pooling layers work, the building blocks of convolutional neural networks.