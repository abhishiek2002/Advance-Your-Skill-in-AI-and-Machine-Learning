Viewing the effect of different filters
In the previous movie, we saw how we could apply a convolutional kernel to extract feature maps from the underlying image. We displayed the result of applying the convolutional kernel, that is, the feature map obtained at the output of a convolutional layer. We then passed the output of the convolutional layer through a pooling kernel and saw the resulting image as well. Now there were lots of operations we had to perform for this. So if you're going to explore the different kinds of kernels that we can apply to input images, we need to set all of this up as a function. And that's exactly what I have done here. All of the individual operations that we performed in the previous movie, I've brought into one function; apply kernel and show. This takes the image tensor as an input argument and the kernel that we want to apply to the image. The code from line 2 through 22 is the same code that we've seen before. We apply the convolutional kernel to the input image, view the feature map, pass this feature map through a pooling layer and view the result. And we plot the output of the convolutional layer and the output of the pooling layer side-by-side. Now let's apply different kinds of convolutional kernels to the input. Here is a kernel that detects vertical edges in the input. This is the vertical edge kernel. This particular vertical edge detector is referred to as a Prewitt filter. Observe that the first column contains all negative ones, then the second column zeros, and the third column positive ones. This particular set of weights for the kernel allows the kernel to detect vertical edges. I'm going to invoke apply_kernel_and_show, pass in our img_tensor, and the vertical_edge_kernel. And this is what the result looks like. The image on the left is the output of the convolutional layer and the image on the right, the output of the pooling layer. Notice the image on the left, the vertical edges are highlighted in that image. The image on the right is the same as the input, but with an aggregated effect. Now that we've done vertical edge detection, let's take a look at a horizontal edge kernel. You can see that the weights of this kernel are similar to what we used for the vertical edge detector. But the same kernel weights are arranged horizontally and not vertically. We have a row of negative ones, then a row of zeros, and then a row of positive ones. And here is what the result of the horizontal edge detector looks like. On the left, you can observe that the horizontal lines or edges in the image are emphasized far more than the vertical edges. And on the right, we have the pooling output, which is just a sub-sampled and aggregated version of the image on the left. Next, let's take a look at another filter. This is the Sobel filter for vertical edge detection. Once again, the first column comprises of negative values, the second column of zeros, and the third column of positive values. The Sobel filter works similar to the Prewitt filter, but it places greater emphasis on pixels that are closer to the center of this kernel mask. Let's take a look at what the result looks like here. Now I can see the vertical edges emphasized in this image on the left, but it's hard for me to tell how this output is different from that of the Prewitt filter. To my untrained eye, it looks the same. Similarly, we have the horizontal edge detector. This is the Sobel filter for detecting horizontal edges. And here is what the result looks like. Again, it's hard for me to tell how this output is different from that of the Prewitt horizontal edge detector. The next convolution kernel that we'll work with is the Gaussian Blur filter. The Gaussian Blur is used to soften the image that we are looking at. And here is the result. If you look at the image on the left, there is definitely a little bit of a smoothing out of all of the edges in the image, that is the blur. And the last convolutional kernel that we'll explore today is the Emboss filter. It's also called a directional difference filter. And this filter generates highlights and shadows in the output feature map to create an effect which makes the image look like an embossed image. And here is what the result looks like. There is definitely a highlighting effect. There is almost a 3D effect that you can see with the car and the image on the left.