Deep convolutional GANs (DCGANs)
In this movie, let's understand what a deep convolutional GAN is and how it's different from a regular GAN. A deep convolutional generative adversarial network is a GAN where each adversary is a convolutional neural network, and these CNNs have certain architectural constraints. The architectural constraints are so set up that they help the adversarial pair learn a hierarchy of representations which help create better-generated images. Now, deep convolutional GANs build upon the original GAN paper. They use the same principle as GANs, the generator and discriminator as adversaries. The only difference is in the architecture for the neural networks that we use for the generator and the discriminator. Both neural networks are architecturally constrained convolutional neural networks. The constraints introduced in these architectures help the CNN be more stable during the training process of the GAN. The authors of the paper on deep convolutional GANs found that it was hard to use traditional CNN architectures for the generator and the discriminator. They encountered difficulties in scaling GANs using these architectures, which is why they developed this constrained architecture that they call the deep convolutional GAN. The original paper that introduced deep convolutional GANs was published in 2016. So this was about two years after the original paper on GANs. The deep convolutional GANs paper is by Alec Radford and other authors. And if you're interested in finding this on arxive.org, the link is right here. Here are the changes made to the original convolutional neural network architecture. The pooling layers that we use in traditional CNNs are replaced with strided convolutions. Strided convolution layers allow the network to learn its own spatial downsampling of input feature maps. Another change is the use of batch normalization layers in both the generator as well as the discriminator. Batch normalization stabilizes the learning process of the GAN by normalizing the input to each unit to have zero mean and unit variance. In typical CNN architectures, the convolutional and pooling layers are followed by fully connected deep layers, and deep convolutional GANs actually eliminate these fully connected layers. The authors found that by eliminating these deep layers, they could connect the output of the generator directly to the input of the discriminator, and that worked well. The authors also found that the results were good when they used the ReLU activation in the generator for all layers except the last convolutional output layer, and that used the Tanh activation function. These activation functions help the model to learn more quickly to saturate and cover the color space of the training distribution. And finally, they used the LeakyReLU activation in the discriminator and found that this works well for high-resolution modeling. Now I'll just dive into the first three architectural constraints in a little more detail, starting with replacing the pooling layer with strided convolutions. The authors found that global average pooling increased the stability of the model but hurt model convergence speed. Instead, they just used strided convolutions in the discriminator to downsample inputs and transposed convolutions in the generator to upsample inputs. Another important constraint, they added, was the use of batch normalization layers in both the generator and discriminator. Batch normalization recenters the output of each strided convolution and transposed convolution layer to have a mean of zero and unit variance, and this mitigates a lot of issues that are encountered while training a GAN. Batch normalization helps deal with issues that might arise due to poor initialization of the network. Batch normalization also helps with gradient flow through models that have deeper layers, and it mitigates the problem of vanishing gradients that can stall the model training process. Batch normalization also helps prevent mode collapse. This is where the generator learns a single data point that effectively folds the discriminator, and then collapses to just produce that data point over and over again. Batch normalization is applied to all layers except the generator output layer and the discriminator input layer. When batch normalization was used with these layers as well, this resulted in sample oscillation and model instability. Another change was eliminating the fully connected layer at the end of the convolutional layers, and this greatly improved model performance. The first layer of the generator in the GAN takes in a uniform noise distribution, Z, as the input, which is then reshaped to a four-dimensional tensor, and this is the start of the convolutional stack. Here is the generator architecture that was proposed in the deep convolutional GANs paper. We'll essentially be mimicking the architecture. Only the depths of the feature map in the individual layers might vary. Observe the latent noise that is fed into the generator, which is then shaped into a four-dimensional tensor. The feature maps in the tensor get larger and larger as they pass through the layers. Start with 4 x 4 images, then 8 x 8, then 16 x 16, and then 32 x 32. And finally, we end up with a 64 x 64 three-channel image, that is the generated image from the generator. The architecture for the discriminator is a mirror image of that for the generator. The discriminator takes in a multi-channel image at the input, it downsamples the input using strided convolutional layers till finally it produces a single output, the probability score of whether the input image was real.