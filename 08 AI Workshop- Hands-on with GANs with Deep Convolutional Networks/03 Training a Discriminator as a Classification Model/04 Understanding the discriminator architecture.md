Understanding the discriminator architecture
In this movie, we'll set up the discriminator that we'll train to classify real images and fake images. And as we've mentioned before, this discriminator is going to have an easy job to do. This discriminator will use strided convolutional layers that can be used for downsampling or upsampling your input images. Strided convolutions allow the network to learn its own spatial down or upsampling. The discriminator will not be using any pooling layers. The implementation of the discriminator is taken from this PyTorch DCGANs Tutorial. We'll be using the same architecture for the discriminator as in this tutorial, which in turn has been inspired from the original DCGANs paper. The dataset that we'll be working with is different. All right, we are ready to set up the discriminator for classification. Let's specify a few parameters. nc = 3 specifies the number of channels in our input image. For color images, this is equal to three. ndf is the variable that we'll use to represent the size of the feature maps in the discriminator. The number of feature maps that we produce at the output will essentially be a multiple of this ndf, and the learning rate we'll use for the optimizer in the discriminator is 0.0002. Now, the original deep convolutional GANs paper recommended a certain way to initialize the weights or the parameters of the model before you start training, and this function essentially defines that. The authors of the original paper specify that all weights should be randomly initialized from a normal distribution, with a mean of 0 and a standard deviation of 0.02. This weights_init function takes in a neural network model as an input, and reinitializes all its weights to match the criteria set by the original paper. On line 6, we initialize the weights of the convolutional layers and on lines 9 and 10, we initialize the weights of the batch normalization layers that exist in the discriminator. Next, let's set up the discriminator itself. The discriminator class inherits from the nn.Module base class, and the neural network that makes up the discriminator is defined in the init function. You can see on line 5 that this neural network is simply a sequential stacking of layers. The layers include convolutional layers, batch normalization layers, and the LeakyReLU activation function. Now, the first strided convolutional layer is on lines 7 through 14. Observe, just above it, I've specified in a comment the dimensions of the input that's fed into this layer. These are the dimensions of the input images in our training data set, number of channels multiplied by height and width, 64 x 64. For the first convolutional layers, the number of channels at the input in channels is equal to nc. This is 3, remember. The out_channels defines the number of feature maps generated at the output, and that's equal to ndf for the first layer. Remember this is 64. The kernel size we use is 4, we have a stride of 2 for the kernel, and a padding of 1, and no bias, bias is false. This convolutional layer is followed by a LeakyReLU activation function with a slope of 0.2. In practice, the LeakyReLU activation, which has a small negative slope, has been shown to greatly improve the performance of the discriminator in a GAN. The LeakyReLU greatly mitigates the problem of dying or saturated neurons. The first strided convolutional layer with the LeakyReLU activation is followed by a second one. The second convolutional layer is defined on lines 18 through 25. Notice the size of the input that's passed into this second convolutional layer, (ndf) x 32 x32. The output of the previous convolutional layer is an input to this convolutional layer, and the output of a convolutional layer we know can be computed using a formula that includes the size of the original image, the stride, the padding, and the size of the kernel. in_channels, that is, the number of channels in the input is equal to ndf, and this should match the out_channels of the previous layer defined on line 9, that was also equal to ndf. This layer will produce many more feature maps, ndf multiplied by 2, so 128 feature maps. The second convolutional layer is followed by batch normalization defined on line 26, which recenters the output of this layer to have a mean of zero and unit variance. The use of batch normalization in the discriminator helps mitigate many problems that we encounter in training a GAN, problems of poor initialization. Better propagation of gradients through the deeper layers of the model mitigates vanishing gradients and so on. So the batch normalization layer is what we apply. And then that's followed by the LeakyReLU activation. The third stack of layers seen here at the bottom of the screen on lines 30 through 39, is essentially similar to the second stack, strided convolution, followed by batch normalization and LeakyReLU activation. The in_channels of this layer on line 31 match the out_channels of the previous layer on line 20. And the comment on line 29 gives us the size of the input fed into this layer. Observe that the height and width of the feature maps are getting smaller, they are now 16 x 16. The strided convolutions are downsampling the image. The fourth stack of layers is here at the bottom, defined on lines 42 through 51. Again, these are similar to the previous stack and need no explanation. And finally, we have the last convolutional layer of the discriminator defined on lines 54 through 61. This is not followed by a batch normalization layer as per the original paper. The out_channels here is equal to one because the classifier produces a single output, a probability score indicating whether the input image was real or fake. Observe the Sigmoid activation at the final layer of the discriminator. The sigmoid activation is used because it generates output in the range 0 to 1, which is essentially a probability score for the input image. The forward function here in this class is the forward pass through the neural network. The input x is simply passed through the discriminator to generate a probability. Now let's instantiate the discriminator. Initialize its weights using the weights_init function that we had defined, and print out the layers of the discriminator. Just to note, on line 1, we move the discriminator model's parameters to the GPU device, which is what we'll use for training. At this point, we have the discriminator set up and ready to be trained as a classification model.