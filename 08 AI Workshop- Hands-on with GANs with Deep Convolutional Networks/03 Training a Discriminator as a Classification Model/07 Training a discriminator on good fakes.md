Training a discriminator on good fakes
Next, we'll actually train the discriminator. And again, the parameters and the steps we follow are the same as in the previous demo. So I won't repeat the same information over and over again. Here is where we set up variables with the number of channels, the size of feature maps in the discriminator, and the learning rate for the optimizer. Next, we set up the function to initialize the weights of the discriminator based on the recommendation of the original DCGANs paper. Then, of course, we instantiate the class for the discriminator. This is the same discriminator network that we saw in the previous demo, and that we explored in a lot of detail, so I won't go through the explanations again. Notice that we have convolutional layers, batch normalization layers, and the LeakyReLU activation, and the last convolutional layer of the discriminator, of course, has the sigmoid activation. Now, after we've set up the discriminator, let's instantiate the discriminator and move it to the device that we'll use for training, initialize its weights. And here is what the discriminator looks like. We'll use the binary cross-entropy loss function for the discriminator and the Adam optimizer to update the weights of the model parameters. We'll set up the training loop exactly as we did before. Make sure you move the images and labels to the GPU device, and we'll be training on good fakes and real images. Now training will run for two epochs, and at the end of two epochs, we'll see how the discriminator performs. Let's quickly look at some of the images from the first batch of the test data, along with the ground truth labels for those images. You can see, these are the images and these are the ground truth labels. Let's take a look at the predictions from the model, make a forward pass through the discriminator, get the outputs. Make sure you round the output so you get classes or categories as predictions. And then we'll display the predictions from the model, along with a grid of images from the first batch of data. Now, I found it hard to tell how well the discriminator did, just by looking at the categorizations from the discriminator. Let's actually compute the accuracy of the discriminator using the same code as in the previous demo, and you can see that the discriminator's accuracy has fallen to 95 percent. Now mind you, for a normal classification model, this is still great, but you can see how the accuracy, which was 100 percent when we actually had bad fake images has fallen to 95 percent, now that the fakes generated are better. Again, I'll use the same code as in the previous demo to get the accuracy for each category or class. So the accuracy for the good fakes and the accuracy for the real images. One change I've made in the code here is to set up two variables; all_labels and all_predictions. all_labels will hold all of the ground truth labels from the test data, and all_predictions will hold all of the predictions made by the model on the test data. And within the loop where I make the predictions on line 16 and 21 respectively, I populate the all_labels and all_predictions lists. Let's take a look at how this model performs on the real and fake images. The accuracy for the good fakes is 96 percent. That means 4 percent of those images were misclassified as real images, and the accuracy for real images is 95.6. So 4.4 percent was misclassified as fake. So really, the improvement in the generator is pretty clear here. Now I'm curious about the images that the discriminator wasn't able to classify correctly, where the discriminator got things wrong. In order to do that, I'm going to set up a helper function here called show that takes in an image and a title and just displays that to screen. Next, let's actually try to identify the misclassified images from the model. The first for loop iterates over all batches of data in the testloader, that is, the test data set. The second for loop iterates over all of the predictions of the model, which is stored in an all_predictions variable. We get the predicted class from the model and the actual class from the ground truth labels, and then we only display those images where the predicted class is not equal to the actual class. Let's run this and take a look at the mispredictions from the discriminator. The model predicted that this was a fake image, but this is actually a real image. Here is another one where the model predicted that this was a real image, but this is actually a fake. Doesn't seem like a great fake, but the model still got it wrong. Again, here is a prediction from the model of fake, but this was a real image, and there are many more here. And this actually makes it very clear that as the generator generates better and better fakes, during the training process, the discriminator performance will get worse.