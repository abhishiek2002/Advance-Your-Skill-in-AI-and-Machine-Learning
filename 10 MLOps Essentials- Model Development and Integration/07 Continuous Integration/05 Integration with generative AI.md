Integration with generative AI
- [Narrator] How is model integration done when it comes to generative AI use cases? Generative AI models are huge, and they take significant resources to train, deploy, and serve. Most popular generative AI models, are hence used through a cloud provider service like OpenAI. Even with open-source models, it is preferred to use the deployed versions on popular platforms like AWS and GCP. Hence, the integration work involves testing the generative AI application with the model service, and ensuring that all functionality works as desired. What are some key considerations for integration testing with generative AI? The first key activity is to focus on how the generative AI model is integrated into the application. This indicates resources provisioning, bandwidth provisioning and security. Prompts for GenAI are the integration code between the application and the GenAI models. These need to be used within the application and tested with the model. In cases where the prompts can be changed by the user, test coverage is critical to ensure that all use cases are addressed. Vector databases can be used for retrieval augmented generation-based applications. These databases also need to be part of the integration testing. If these GenAI applications are AI agents, then the tools used in these agents and their integration points with external applications also need to be tested. Guardrails may be used with GenAI applications for safety and security reasons. Popular guardrails include privacy protection, hallucination, and harmful content filtering. These guardrails also need to be included during integration testing to ensure that they work as desired when deployed in production. From a performance point of view, latency and cost for GenAI applications need to be measured during integration testing as they have a significant impact on user experience and budgets.