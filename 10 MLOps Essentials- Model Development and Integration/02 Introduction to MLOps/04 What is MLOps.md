What is MLOps?
- [Instructor] Let's get now to the topic of this course, MLOps. What is MLOps? MLOps is a set of best practices that helps manage the creation and use of ML artifacts through efficient workflows, collaboration and tracking. MLOps is not a specific product or technique. It is a set of processes and best practices to build and run ML supported by automation and tools. What are the elements of MLOps? MLOps extends the DevOps methodology to building and serving machine learning solutions. It integrates the activities of data engineering and model development into the software engineering and deployment life cycle. In addition to the software engineering artifacts of code and records, it manages the machine learning artifacts, data and models. It enables continuous model development and integration, thus following an agile process to reduce time to market. MLOps deals with model deployment and serving. It also includes monitoring, performance analytics and generating feedback for further improvements. It helps manage the ML processes through automation and tools to improve efficiency. What does the MLOps lifecycle look like? It looks similar to the DevOps lifecycle. There are three groups of activities. The software engineering and operations groups are borrowed from DevOps. Additionally, there is a machine learning group too. Let's look at the various activities and how they integrate with each other. The process starts with defining the requirements for the ML project and a corresponding design. The design would include both non-ML parts like APIs, services, databases, user interfaces, et cetera, and ML pipelines like data engineering pipelines. This is then used to develop the non-ML parts of the overall solutions. The requirement would then also feed into data engineering for converting raw data into usable features for ML. Then there is a continuous training cycle where a model is built and refined until it meets the stated requirements. Models that are created are managed under a model governance framework. As models are built, they are also integrated continuously with the non-ML code. Continuous here would be specific small intervals like each print or each week. On passing integration, the model and the non-ML code are packaged together and delivered. Now the operations process kicks in. Continuous deployment takes care of deploying the approved packages to production. The model is then served to users. The performance of the model is monitored to ensure that it stays within the expected thresholds. Model performance information, as well as model drift and bias information is fed back into the model governance for tracking and evaluation. Input is also provided in the requirements to see if changes or improvements are needed on the ML or non-ML functions. Finally, feature and label data from production databases is captured and fed into the data engineering pipeline to create new data sets. If model governance determines that the model need to be retrained, then it kicks off another training cycle with new data. Having seen its life cycle, let's explore the principles of MLOps in the next video.