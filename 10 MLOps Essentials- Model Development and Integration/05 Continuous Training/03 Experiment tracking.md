Experiment tracking
- [Instructor] One of the critical areas for MLOps is the tracking of ML experiments. In ML training, multiple runs of building and validating the model happens as the data scientists work towards their expected performance goals. Each ML training run is considered an experiment. Experiment tracking helps manage the evolution of an ML model towards stated performance goals. Experiments should be tracked continuously to analyze if improvements are made and decide on the next set of experiments to run. What should be tracked for an experiment? We begin with the model itself. All the model set up including the ML algorithm being used and the architecture of the model for deep learning models need to be tracked. Also the hyper parameters set up for the specific experiment should be tracked. Next comes the input to modeling. The specific data set and its version should be linked to the model. The training validation and test splits should also be tracked. With the model configuration and inputs, it should be possible to recreate the specific experiment and reproduce the results. Then comes the output produced. This includes the model itself in some serialized form like a pickle file. There are also performance measures like accuracy, errors and F1 scores that need to be tracked. Once the results are obtained, the data scientist would analyze the results and compare them against earlier experiments. This comparison should also be documented and tracked. All discussions, findings and next steps should be tracked as documentation and associated with the experiment. What are the benefits of experiment tracking? Experiment tracking helps measure the impact of changing model parameters. It also helps identify model behavior due to changes in training data. Data scientists can verify if the project is moving towards the stated requirements and goals and take corrective action with experiment tracking. The results of experiments can help decide if the model needs to be promoted to production. This analysis can be automated along with decision criteria for promotions, thus leading to an automated experiment analysis and promotion pipeline. One key aspect to remember is the amount of activity needed for experiment tracking. Doing this tracking manually is time consuming and prone to errors. It's recommended to use the right tools built for this purpose and integrate them into the ML training pipelines. This way data is automatically added to the tool during experiments and tracked over time.