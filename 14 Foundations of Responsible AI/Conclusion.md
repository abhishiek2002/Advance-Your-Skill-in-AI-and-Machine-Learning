AI regulation and applying responsible AI frameworks
- Now that you have a solid foundation of the theories, methods, principles, and tools used to create responsible AI systems, consider what steps are within your control. In your role, you may be tasked with building models with no empowerment to speak up about bias issues. Take this as your call to action to point out issues when you see them and suggest alternative strategies to avoid harming users. This can mean suggesting a model shouldn't be deployed, pushing for additional data collection, or pushing for different business uses of ML. For those who help guide teams to deliver products on schedule, allow more time for bias to be identified and mitigated in the design and deployment life cycle. This process can be difficult and is often time-consuming, but the delays to a product release may be necessary to avoid creating products that perpetuate bias or cause physical, mental, or financial harms to users. If you lead a team or department, insist on adopting frameworks such as key decision tracking so you know how some outcomes developed based on the decisions made in the design and development process. Insist on evaluating for fairness amongst your models. Prioritize the experience of marginalized users and closely monitor for model and fairness drift. If none of those apply to you, don't leave these important lessons here on LinkedIn. Urge your teams to investigate if your training data is biased or imbalanced and what mitigation steps and recourse is available for users who've been harmed by your AI systems. "We have to figure out how to slow down, "and at the same time, invest in people and communities "who see an alternative future. "Otherwise we're going to be stuck in this cycle "where the next thing has already been proliferated "by the time we try to limit its harms." If you're interested in learning more, I've compiled a reading list to accompany this course filled with resourceful books and articles to help you grasp the concepts covered in this course more deeply, and turn those ethical principles into actionable mitigations. For organizations that need more help with ethical AI strategy, conducting algorithmic impact assessments, ethical R&D, and responsible AI product marketing, reach out to firms like Ethical AI Champions to help navigate your team through the challenges of operationalizing AI ethics. Remember, we're just at the beginning of the shift to responsible AI. It requires effort from everyone, and no contribution is too small. We have the power right now to change course and develop AI in ways that put people first. Don't be discouraged that it may take more time and careful consideration than continuing down the easy path. We'll find that our strategies and products are more aligned with our goals and increase user trust along the way. I'd like to give special thanks to my technical reviewer for this course, Lynne Guey. Thank you for your tremendous help reviewing the content. And thank you for taking the time to learn about responsible AI and making the future one in which AI works to benefit everyone.