Calculating consequences
- All different types of people interact with AI systems. And therefore, AI systems impact people differently. In addition, people may interact with the system more or less voluntarily. A bank developing an AI application that automates the assessment of loan applications, forces both customers and employees to interact with it. The loan application assessment system decides whether or not people will have access to loans. In other cases, especially marketing, people may not realize the recommender system that influences their content is actually influenced by their past viewing behavior. The recommender system influences what they're exposed to and can sway their decisions. When considering how to build responsible AI, we have to consider the unintended consequences of our models. One of the reasons responsible development is difficult is that AI can create more hidden errors. Models are merely statistical representations of the observable features such as facial muscle movement, hair length or skin tone. And fail to represent unobservable concepts such as emotions, gender or race. Machine ethics is concerned with ensuring that the behavior of machines towards human users and perhaps towards other machines as well is ethically acceptable. Ideally, AI reasoning should be able to take into account societal values, morals and ethical considerations, weigh the respective priorities of values held by different stakeholders in various multicultural contexts and explain its reasoning and guarantee transparency. In a survey by Avanade Insights, they found that 83% of business and tech decision makers feel that digital ethics is a foundation for successful AI. However, there's an execution gap between our stated intentions and what we do in practice. There are two kinds of consequences. Intended and unintended. Intended consequences are the change or impact you're looking to make. These are your project requirements. But try to reframe these in terms of the impact of the world, as well as your business aims. Unintended consequences are what could happen as a result of actions that you do not anticipate. Additionally, consequences has a negative connotation, but all consequences aren't negative. In the case our AI helps reduce the number of patients who suffer from undiagnosed diseases, that would be a positive outcome. Let me introduce the concept of consequence scanning and how to make it part of your development process. Many leaders of the biggest tech companies of our time have admitted they simply did not think of the consequences of what they were creating. As a result, companies have suffered massive reputational damage, missed opportunities to harness human diversity to solve new problems and cause an immense amount of harm to various communities. Consequence scanning is an action your team can take to involve diverse perspectives and brainstorm potential consequences of releasing a product. There are three main questions we aim to answer with a consequence scanning event. Take a moment to write these down. What are the intended and unintended consequences of this product or feature? What are the positive consequences we want to focus on? And what are the consequences we want to mitigate? Answering these questions helps us share knowledge and expertise so we can map the potential impact of a product or feature. In the next video, we'll talk through an exercise in consequence scanning.