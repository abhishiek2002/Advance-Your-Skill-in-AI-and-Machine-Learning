Attention mechanism in sequence to sequence models
- [Instructor] Now that we've understood the importance of attention, let's see how we can include attention models in sequence to sequence networks. Now here is the encoder and decoder network for language translation. Now, I've set it up a little differently so that we can clearly see where attention fits in. At the bottom here I have the encoder network. X1 through XT are the input to the encoder RNN at different time instances. These are the input words in the sequence. h1 through hT represent the hidden state of the encoder RNN. Again, at different time instances. You can think of h1 through hT as the hidden state for the individual words in the input sequence. Up here on top I've represented the decoder recurrent neural network. The output of the decoder at any time instance is yt, and you can see that the output at time instance t-1 is connected back into the input at time instance t. So y1 is connected to the second neuron, y2 is connected to the third neuron and this goes all the way through. S1 through SK represent the hidden states of the decoder network, and observe that the hidden states of the decoder layers are connected to one another. That is the hidden state at time instance t is fed into the decoder layer at the next time instance. In the original encoder-decoder model, the final hidden state of the encoder is fed as an input to the decoder to start the language translation process. This is what we highlighted as a bottle neck in the previous video. Now, what do a attention models do? Attention models create a shortcut mechanism that connects the context vector, Ct and the entire source input X. So you can see there is a direct connection from the hidden state of the encoder RNN layers through the context vector and through the decoder. The context vector here encapsulates the attention mechanism that forces the decoder to pay attention to the relevant portions of the input. Now, how does attention mechanism help this shortcut from the input to the decoder that produces the output ensures that each output of the decoder has access to the entire input sequence, not just a hidden state representation. The context vector enables the decoder to selectively pick out specific elements from the sequence to produce the output. So the decoder can specifically look at those portions of the input that are the most relevant at the current time step. Going back to our visualization here, here is the attention mechanism that allows the decoder to selectively look at the relevant portions of the input. Let's see how this attention mechanism works. A context factor is generated at every time instance and fed as an input to the decoder at each time instance. The context vector uses weights to determine which portions of the input sequence are important to generate the output at any time instance t. So it's pretty obvious that the context vector will be different for different time steps. At every time step to the decoder, the context vector serves as an additional input into the decoder layer. So along with all of the other inputs, we also pass in the context vector. That is the attention mechanism. You can see that the output of the decoder at each time step depends on three separate components. There are three separate inputs going into a decoder layer. Now, what are these three instances? The hidden state of the previous decoder layer, that is St-1. The word that was generated in the previous time instance, that is yt-11. And then we have this additional context vector Ct, which tells that decoder layer what portions of the input to pay attention to at this time step. So how do you get this context vector? It's computed using a weighted combination of the encoder hidden states. And the weight assigned to a particular hidden state indicates how important that hidden state is. These weights are referred to as alignment weights. Now, these alignment weights change at every time step. That is the weights assigned to the hidden states of the input vary over time. There are different weights at different time instances. The alignment weights represented by alpha are different at different steps in the sequence. The weights depend on the word that is to be predicted by the decoder RNN. The weights are automatically set up in such a manner that they highlight the most important input components for any part of the output at any time step. Here is a mathematical formulation for computing the context vector that is an input to the decoder at each time step. hJ here is the hidden state of the encoder for different inputs in the sequence. The hidden state corresponding to the different words in the input sentence. The hidden state does not change over time, which is why you don't see ht here in the subscript. Alpha here refers to the alignment weight vector. Now, the weight vector has weights for different inputs in the sequence, and the weight vector changes over time. That's why you see the t subscript. And because the weight vector changes over time, the context vector also changes over time. So weights will vary at different time instances, and the context vector will change accordingly. And finally, one last thing to note is, the sum of all of the alignment weights at any time instance will be equal to one. Think of these alignment weights as probabilities assigned to each input in the sequence, the probabilities have to sum to one.