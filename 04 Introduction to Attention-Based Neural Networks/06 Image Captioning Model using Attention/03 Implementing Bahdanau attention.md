Implementing Bahdanau attention
- Next up, we define the attention module that allows our decoder RNN to pay attention to important parts of the input image. We are using Bahdanau's Attention, that is additive attention, and you'll see that the operations that we perform on the features are the operations that we discussed for Bahdanau's Attention. Initialize the attention module by specifying the size of the encoder hidden state, the size of the decoder hidden state, and the size of the attention. These are the parameters of your attention module, initialize the member variable attention size to the attention size. In Bahdanau's Attention, we pass the encoder and decoder hidden states through a weights layer, and this is where we initialize the weights layer. full_A here is the trainable weight vector that generates the alignment scores. Here is what a forward pass through the attention model looks like. As an input, we accept the feature map representations from the encoder output and the previous decoder hidden state. In order to perform our operations here in the attention model, we add an extra one dimension to the decoder hidden state using the unsqueeze method. We pass the encoder output through the encoder weight to get the encoder attention. In a similar way, we pass the decoder hidden state through the decoder weights to get the decoder attention. In Bahdanau's Attention, the encoder output and the decoder hidden state output are both combined. They're added together and passed through an added layer that gives us the combined state and then we pass the combined stage to our linear weights layer that's a trainable weights layer to get the attention scores. These attention scores are 49 element vectors corresponding to each image. The feature map representations, that's the output of our resident model, have seven by seven feature maps. Seven by seven gives us 49 elements of the input feature map and these attention scores tell us how much attention we should pay to each of those 49 elements. The attention scores need to be converted to probabilities, so we pass them through a softmax layer. This gives us the attention weights for each of the 49 features in the input image. And finally, we use these weights to generate a context vector. This context vector will be fed into our decoder. The attention model returns the attention weight, as well as the context vector.