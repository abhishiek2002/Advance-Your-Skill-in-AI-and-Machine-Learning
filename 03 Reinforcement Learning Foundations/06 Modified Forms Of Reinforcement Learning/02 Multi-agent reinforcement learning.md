Multi-agent reinforcement learning
- [Instructor] So far, I've talked about the learning done by a single agent. How about the learning in a situation that is more realistic, with different agents? They can be trained using reinforcement learning to reach a common goal. This means they are cooperative, or they could have different goals, this makes them competitive. Or they could be general, neither cooperative, nor competitive. This makes us develop safe artificial intelligence systems, that learn in the same setting, as they are supposed to perform with others. For example, if you're training a group of reinforcement learning agents to play football, those on the same team will have to act cooperatively, to score goals, while agents in opposite teams will be competitive. Another typical example, is with autonomous vehicles. Multiple agents could be made to drive cars in simulation, and learn from each other.