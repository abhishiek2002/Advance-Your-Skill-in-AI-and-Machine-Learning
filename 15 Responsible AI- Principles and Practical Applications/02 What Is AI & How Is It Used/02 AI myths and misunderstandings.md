AI myths and misunderstandings
AI is created by humans, ultimately to help individuals and society. While it holds great potential, AI also has significant limitations. As AI tools become more pervasive in our society, it's important for us to understand their limitations and carefully balance their benefits and risks. In the previous video, I introduced the concept of artificial intelligence, or AI, and I explained how the most common form of AI, machine learning, works, using the example of an algorithm trained to classify any object that is round and red with a stem as an apple. Let's explore this example further. Of course, we know that not all apples are red. Thus, the model we trained to identify a red apple would likely misclassify this green apple as not an apple. This error is referred to as a false negative. Let's consider another example. Suppose we're training a machine learning algorithm using a set of excellent employees we've had in the past in order to help us decide which new individuals we should hire. We would consider factors such as relevant work experience, schooling, and skill sets. Now it just so happens that we work in an industry that employs similar types of people, So the model will essentially end up identifying these types of people as potentially good employees. When we apply this model to assess a different type of potential employee, the model will likely classify that person as not a good fit for the company. This is an example of machine learning bias. We're going to explore the risks of machine learning bias in more detail later in this course. Dr. Brandy Nonake, Director of the Citrus Policy Lab at UC Berkeley, has noted that Artificial intelligence is taking on a more central role in high-stakes decision-making within our most critical social institutions. It has entered into our hospitals, courthouses, and employment offices, deciding who gets insurance, who receives parole, and who gets hired. Myths and misunderstandings about AI relate to its accuracy, objectivity, responsibility, and sentience. Accuracy. AI systems are very good at executing rules-based processes and following patterns and steps they have been trained on. If the training dataset is inadequate or ill-conceived, however, the AI system will produce inadequate or ill-conceived results. Objectivity. As I mentioned at the beginning of this video, AI is created by humans. Therefore, AI systems naturally reflect human values and norms, and hence they can be prejudiced and biased. Sarah Zhang, a leading journalist who covers AI, has cautioned that we know already that although machine learning has huge potential, data sets with ingrained biases will produce biased results. Garbage in, garbage out. Responsibility. Research has shown that people have a tendency to overly trust automated decision-making systems, even ignoring contradictory information. This is automation bias and can be detrimental to the responsible use of AI. It is important that people understand that AI systems have no sense of responsibility. As such, appropriate oversight mechanisms should be put in place to support responsible development and use of AI. I will discuss strategies for this later in the course. Sentience. In the previous video, I explained the capacity of AI ranges from narrow or weak to general or strong. As a reminder, narrow AI can perform simple tasks like identifying patterns in new data based on what the model learned from a training data set, while general AI can execute generalized tasks much like a human. AI sentience, or artificial general intelligence, refers to a a machine that is self-aware, having consciousness, and being capable of feeling emotion. While science fiction films often depict sentient AI, for example in the movies Her and Terminator, truly sentient AI is still a long ways away. In the next chapter, we will dive deeper into the benefits and risks of AI. I encourage you to take a moment now to consider how you already engage with AI and how it influences you.