Challenges with serving models in production
- [Instructor] What kinds of challenges exist in serving ML models in production? What types of problems can occur? Resource choking and associated system performance degradation is a common problem if enough compute and storage resources are not allocated to the model or service. This increases latency and may cause the model to crash. The input data received by the ML service may be incomplete or corrupted. This can be intentional or may happen due to upstream application issues. This will result in incorrect predictions that may have downstream implications. Application-related defects and exceptions can happen across the application stack, which may impact how the model executes and behaves. Again, it can lead to degraded performance or failures. ML models are also susceptible to several security risks, like data poisoning, adversarial attacks, or attack vector exposure that can compromise model behavior and outputs. Drift may occur in how the model performs in production. This leads to incorrect outputs, which in turn impacts the effectiveness of the applications. Bias and fairness issues in predictions may also occur. This, if exposed, can lead to loss of trust with the model. We will specifically discuss model drift and bias in this course and explore ways of detecting and overcoming these two challenges.