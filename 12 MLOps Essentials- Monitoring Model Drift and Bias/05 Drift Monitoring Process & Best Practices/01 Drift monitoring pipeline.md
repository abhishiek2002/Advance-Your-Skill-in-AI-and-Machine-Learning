Drift monitoring pipeline
- Having discussed techniques for detecting drift in the previous chapter, let's discuss the process and best practices for drift monitoring in this chapter. Let's begin with creating a drift monitoring pipeline. A robust drift monitoring pipeline is key to effective measurement and detection of drift metrics. What does a typical drift monitoring pipeline look like? We begin with the ML service or model that is used for inference in the production environment. For each inference request, the service needs to be instrumented to collect the features used and the predictions obtained. This information is then pushed into a drift database. There could be data collection, chewing and consolidation processes that may be used to achieve this goal in a large cluster. Then, labeling may be used to add ground truth or true labels to the captured data. This can be done by manual or automated labeling. Using the ground truth and predictions, we can compute concept drift measures like accuracy and F1. This information is computed over several time intervals to observe the trend. Similarly, using the features from inference, we can also compute feature drift measures over multiple time intervals. The metrics can be provided to the user through an analytics dashboard. The dashboard helps the data scientists understand if drift is happening and if it requires retraining. There can be automated alerts too if drift is observed beyond a set threshold. This pipeline can be used to observe multiple models deployed in production.