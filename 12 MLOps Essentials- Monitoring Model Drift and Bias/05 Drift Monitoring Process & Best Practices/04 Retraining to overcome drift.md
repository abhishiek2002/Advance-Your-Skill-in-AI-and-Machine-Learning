Retraining to overcome drift
- [Instructor] What are the best practices in retraining the model to overcome drift? The first important step is to update the training data to accommodate for the changes in feature target relationships. Analyze the business change that has happened. Use the help of domain experts to understand and categorize this change. Determine how much of the training data needs to be updated or replaced. Is the change happening in a specific class or across the board? Do we need to replace the entire training data set or simply make additions to it? Remove use cases that are no longer applicable in the training data set. Add new use cases that have popped up after the last model training cycle. Ensure that data distributions are balanced for each of the features after doing the additions and subtractions. Review the training, validation, and test splits to ensure that they are random and balanced. How about retraining the model? If changes are being made to the model type, architecture, or hyperparameters, it should be gradual. Try changes one at a time to understand their impact on model performance. Ensure that the updated model works equally well for existing, as well as new use cases. It's important to keep the balance and not over-fit for the new use cases. Test against production data where drift was observed previously and see if drift is eliminated now with the new model. Aggressively monitor the new model for some time to ensure that drift has been alleviated. See if there are other problems that bubble up with the new model. This concludes our discussions around machine learning drift. We will discuss bias and fairness in the next two chapters.