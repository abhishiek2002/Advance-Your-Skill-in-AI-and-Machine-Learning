Introduction to model drift
- [Instructor] In this chapter, we will explore in detail about Model Drift concepts. Let's begin with an introduction to Model Drift. When we train, test and deploy a model, it has a proven level of predictive accuracy. It is expected that the model will continue to have the same accuracy levels in production over its lifetime. A model is considered drifting when its predictive accuracy reduces over time when deployed in production. Let us consider a few examples here. We have three models deployed in production at month zero. The chart shows the observed prediction accuracy of models for the next four months. Let's start with the first model, sentiment analysis which is the green line. It starts with an accuracy of 85%, and over the next four months it oscillates between 85% and 90%. It is staying within the band, and hence considered not drifting. Next, let's look at the intent detection model shown in red. It starts with an accuracy of 85%, but in the second month, it's observed accuracy false to 65% and then stays around there. This is considered a sudden model drift. Next, we look at the obscenity filter model in blue. This model starts at 90%, and its accuracy goes down slowly over time to 75%. This is called slow drift or slow decay over time. When a model is deployed in production, all these types of drifts can happen, but if the model accuracy goes down for a given time period, but comes back into the band for the next, it will not be considered as drift. To help with our discussions around drift, let's discuss some math on prediction probabilities. Let us assume that we have a simple model that takes in features about a patient, and predicts if the patient has diabetes. One of the features is the age of the patient. X stands for a feature and Y stands for a target. So the probability of X or P of X is the probability that a given feature value appears in the population. So if 40% of the patients are over the age of 50, then the probability of age greater than 50 would be 40%. Similarly, the probability of Y or P of Y is the probability that a given target value occurs in the population. So if 10% of the patients have diabetes, then the probability of diabetes equals true is 10%. We then look at conditional probabilities. The probability of X given Y or P of X by Y, means how often a given value of X occurs when a given value of Y occurs. This means the percentage of the time where age is greater than 50, where the patient also has diabetes. The reverse conditional probability is P of Y bar X. This is the probability that the patient has diabetes when their age is greater than 50. The joint probability of X and Y is the percentage of time that both X and Y values occur in the dataset. In this example, it is the percentage of time that a patient has diabetes, and their age is also greater than 50. The probability of Y given X or P of Y by X is computed as the joint probability of X and Y divided by the probability of X. This is the formula that indicates the relationships between a specific value for a feature, and a specific outcome for the target. Drift happens when the probability P of Y given X changes in the real world, but the model does not reflect the same. For example, let's say, after the model is developed and deployed, a magical medication for diabetes is introduced because of which patients above the age of 50 mostly recover from diabetes. The model will not be in-sync with the change, and will continue to predict with its older assumptions. Hence, it'll drift and decay. We will explore drift further in the remaining videos in this chapter.