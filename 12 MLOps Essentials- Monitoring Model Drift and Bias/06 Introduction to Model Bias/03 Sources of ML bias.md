Sources of ML bias
- [Instructor] How does bias enter into the machine learning process and models? Let's discuss some key sources of bias in the machine learning process. The first type of bias is data selection bias. Data for machine learning is usually obtained from a manual process where the outcome is determined by a human. If that human made decisions in a biased manner, then the training data will also reflect that bias. The model built off that training data will carry over the same bias. The next type of bias is group attribution bias. This is generalization of a behavior based on specific attribute values. In ML training, this happens by using some protected attributes like race and gender. The next one is human bias. This is the bias that data scientists themselves exhibit when they expect certain outcomes based on biased hypothesis. For example, a data scientist may think that older men will make more money than young women. If the model testing generates results against this assumption the data scientist would reject that model as faulty. Finally, there is benchmarking bias. Benchmarking is usually done using a sample. If that sample does not represent the entire population in a balanced manner, then benchmarking results may also be biased.