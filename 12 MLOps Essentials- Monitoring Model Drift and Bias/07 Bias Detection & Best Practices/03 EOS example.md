EOS example
- [Instructor] Let's do an example exercise for Equal Opportunity Score now. The code for this exercise is available in the code_06_03 Equal Opportunity Score with sklego.ipynb Here, we first install the sklego package that contains functions for computing EOS. Then, below the credit-approval-training-data.csv file that we used earlier for drift detection, we will identify two protected attributes here, namely AGE RANGE and RACE. For both these attributes, we convert them into binary variables. For AGE_RANGE, we mark category three as privileged. For RACE, we mark categories one and two as privileged. Then, we build a naive_bayes model, and print the accuracy of the training classifier. For computing equal opportunity scores, we use the equal opportunity score function. We provide the sensitive column name as AGE_RANGE, the classifier, the features, and the true label. The function will use the classifier and the features to predict the outcome, and compare it with the true label. It computes the EOS score based on the formula we discussed in the previous video. Looking at the results, we see that the equal_opportunity_score for Age Range and Race are closer to one. Next, we repeat this exercise with another dataset, credit-approval-fair-data.csv. We will follow the exact same steps and generate the EOS. Here, we see that though the score for age range is high, the score for race is low. This means the model built on the new data set is biased for the race attribute.