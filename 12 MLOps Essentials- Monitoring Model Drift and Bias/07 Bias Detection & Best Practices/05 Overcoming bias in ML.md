Overcoming bias in ML
- [Instructor] We discussed how to detect bias in machine learning. Let's now discuss some best practices to overcome bias. We begin with discussing training data collection. Training data is an important source of bias, so ensuring that the training data is unbiased is a great start to building fair models. Training data needs to be validated for the existence of bias. If the data originates from human decision making, then we need to understand and ensure that the decision making was fair. Ensure that all scenarios are sampled equally in the training data. This ensures fair representation for all demographics in the results. Check for equal class representation for each attribute. All classes should have sufficient representation in the data set. Use bias detection techniques to check if there is inherent bias in the data set. Next comes model training. Remove all protected attributes from the training features. Protected attributes should not be used for building models. Even if protected attributes are removed, other attributes may have strong correlation to the protected attributes and hence can act as indirect proxies. This relationship should be understood as proxy attributes may introduce bias in the model. Additionally, after the model is built, check if correlation exists between the predictions of the model and the corresponding protected attributes. Use human oversight to review results and see if possibilities of bias exists in the training process. Finally, we need to look at models deployed in production. Bias also need to be monitored in production data in addition to drift. Bias detection techniques should be used periodically to check if bias exists in these predictions. The input for both drift and bias reduction is the same so the same pipeline can be used. Additionally, use human feedback as much as possible on the predictions to detect if the predictions are biased. This feedback can come from the consumers of the predictions or by explicit sampling of results. This completes our course on model monitoring for drift and bias.