Regularization
- [Kumaran] Regularization is an important technique for managing overfitting in neural networks. Regularization controls overfitting during model training. How does it work? Regularization algorithms provide an adjustment to the model parameters after they are updated. The adjustment reduces the variance in the model by providing a penalty when overfitting increases. There are multiple algorithms available for regularization, the most popular being L1, L2, and L1 and L2 combined. We are not going to discuss these algorithms in detail, but I recommend it for additional reading. They are already implemented in popular machine learning libraries. We can specify a regularizer when creating a hidden layer in Keras. We will compare these options in the next video.