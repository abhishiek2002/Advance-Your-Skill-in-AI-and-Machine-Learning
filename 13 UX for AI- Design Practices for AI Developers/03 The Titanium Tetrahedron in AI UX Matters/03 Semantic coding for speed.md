Semantic coding for speed
- Okay, I am in the GitHub repo for Semantic Kernel. Those of you who are one of the tens of thousands of people who have completed the Semantic Kernel intro training, you'll know that this repo exists, but you might be looking at them like there looks kind of too much for me. So some of you like you've already forked it and they're running, running, running, running, running. Well, this is about, again, UX for AI and you remember the AI notice pattern we described? Here it is laid out and it's open source because if you go to the Build 23 site, this came out just in May and you can watch the entire presentation on this very topic. But let's go to code and let us go to VS Code and going to show you something pretty special. What it is is it's the new Semantic Kernel extension and the way you get it is you go to extensions and you type in Semantic Kernel and there it is. It lets you do quick prompt engineering without any installation of this that GitHub repo, can just get going really quickly. Let's show you how that works. So we go to Semantic Kernel and I have different endpoints available. I want to provide my OpenAI key and let me get that key, one second. And this works with Azure OpenAI or regular OpenAI. And there I have all these endpoints available. Wow, look at all these models we get to try out. And what I can then do is I can make my own functions. Let's start, let's make a function to address latency issues in UX, okay? This is a rumination on how to deal with the fact that models are a bit slow, okay? So the application that is being built is for customers of this type. Going to give it the type of customer as input, we'll show you how that works next. And they are being made to wait and the process is taking too long. Useful copy to provide to the customer to let them know all is okay. Is okay, this is basically asking for some quick copy. This is better than a quick lorem ipsum, right? Let's run that function. And you can see it in the output. It is taking that function and oh, it's asking me for input. I forgot to say within the customers, banking in a retail location, you know that thing, they're like waiting. So you are at a bank and you've got this long line of people, dissimilar to a service, takes you long. We apologize for the wait, we are doing our best to serve you as quickly as possible, thank you for your patience. Isn't that better than lorem ipsum? Anyways you can imagine as a copy generator for things that take too long relevant to your industry, it can go to town that way. Let's say instead however, you wanted to have some quick illustration to place in context. Well, we can use these Semantic Kernel endpoints available for hugging face and we can use their open source text to image models to do something similar. Let's make a plugin for, let's see here, latency is a thing. Making images to surface to users so that they can happily wait if waiting is ever happy. If following application serves users who are blah, no actually this is, let me change that. Let me just jump to the conclusion. Photograph of, it's easy as that, right? Let's not overthink it. We're now going to generate let's say it is a turtle eating spinach. This would never be appropriate in a banking app folks but we're going do this and you need a quick forward position only image, and then voila, you can stick it inside your app, right? So I can load this up and there you go. Hey, turtle, eating spinach. And so that's all happening from within the Visual Studio code extension for Semantic Kernel. We found that a way for more users to more quickly create with Semantic code and also of course, it makes it easier to integrate into your actual code. So please enjoy this new tool and increase your own speed to market.