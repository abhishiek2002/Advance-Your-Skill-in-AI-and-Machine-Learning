What is collaborative UX?
- When you're building a copilot, an AI copilot, it's got to be a collaborative process. You, the developer knows the technology, knows the math. Everyone else doesn't know it as well. So working together as a team, it's really important. Taking that spirit into building the UX of a copilot is key. You want to remember that when you're building a copilot the user is the pilot, and the AI is the copilot. User is boss, pilot. AI is not boss. The second thing to remember is that the copilot is only as good as the pilot. Think about it like working with a boss. Your boss, your past boss. The boss isn't good, the co-pilot's no good. The co-pilot is only as good as the human pilot. CollaboroUX as a philosophy at Microsoft has been evolving rapidly in this copilot era and there's a bunch of people working on it at Microsoft. Shout out to you all. Now, why do you care about building these experiences, these AI experiences? It's because right now, big stuff is happening. (laughs) I'm sure you've noticed since the ChatGPT sonic boom, everyone's noticing that we got to ship AI in the product right now. We need to work together. I love the emoji, the scream emoji. People think it's the "Home Alone" emoji, but it's not. It ties back to artist Edvard Munch and his Scream painting which literally when people saw it for the first time, they thought it represented a truly insane person. This era feels like insanity in many ways and that's why we can actually bring out our worst angels in the process in "How to Speak Machine", I shared how I've noticed over time that if you're curious, you're able to be less afraid and get more inventive. Whereas when you're just afraid, you get destructive. You get afraid and destroy what is coming at you. That's going to happen for a lot of non-tech people. People who are not developers are not going to understand it. So that's why you as a developer have a pretty important responsibility as the folks spearheading these new advancements. So remember, you're building systems that need to engender trust, but not just any kind of trust. Appropriate trust, meaning trust that the pilot understands the AI copilots limitation and establishes the appropriate bounds of trust. Now, as a developer thinking about design, it may be foreign to you, but I grew up as a software engineer from MIT. I loved building things but never knew how to build things for people and went on a journey into design world and wrote a book called "The Laws of Simplicity" 10 Laws to enable you to design better technology products. That's 2006. Over time I realized 10 laws is kind of too much. To simplify, the three laws that matter in the AI era are the law of emotion, the law of trust, and the law of failure. The law of emotion is basically taking into account; you're building these things for people. Law of trust is the fact that if you trust it, it's like a whole different level. You love it. But lastly, when you're designing things, you're going to fail sometimes. Now it turns out that the nature of this new kind of AI is about failure, some success, some failure. It's non-deterministic. You roll the dice and you hope it's right. With the right kind of engineering the right kind of use of the stack, you can up your odds. So the copilot stack is about these different layers of technology with people using the copilots. It's a new way of UX that brings the old ideas of simplicity and design into this new language of collaboration. Collaboration in your team, collaboration between pilots and their copilots.